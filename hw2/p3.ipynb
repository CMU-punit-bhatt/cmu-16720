{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4f4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97a68f63",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7d83a37263ce235f0bb4ef215e570cb",
     "grade": false,
     "grade_id": "cell-be3fe8a24d877d09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"figures/course.png\" width=\"800\">\n",
    "\n",
    "#                                    16720 (B) Bag of Visual Words - Assignment 2\n",
    "\n",
    "     Instructor: Kris Kitani                   TAs:Paritosh (Lead), Rawal, Yan, Zen, Wen-Hsuan, Qichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e00ddf3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93301716fd96b48eea99bc2d171ff33e",
     "grade": false,
     "grade_id": "cell-e15ca317eaa41fb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import numpy as np\n",
    "import skimage\n",
    "import multiprocessing\n",
    "import threading\n",
    "import queue\n",
    "import os,time\n",
    "import math\n",
    "from ipynb.fs.defs.p1 import get_visual_words\n",
    "from ipynb.fs.defs.p2 import get_image_feature, distance_to_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0446c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f68ec46",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6b4bd161f74c53045778dc7514a8ee4",
     "grade": false,
     "grade_id": "cell-5de8321c73982d7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## For Autograding P3, ensure uploading `conf_matrix.npy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c20957e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f4d1f07da6458c74287795f94f96536",
     "grade": false,
     "grade_id": "cell-2147ec14a9f2bf1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Quantitative Evaluation\n",
    "\n",
    "#### Calculating confusion matrix\n",
    "Qualitative evaluation is all well and good (and very important for diagnosing performance gains and losses), but we want some hard numbers.\n",
    "\n",
    "Load the corresponding test images and their labels, and compute the predicted labels of each, i.e., compute its distance to every image in training set and return the label with least distance difference as the predicted label. To quantify the accuracy, you will compute a confusion matrix $C$: given a classification problem, the entry $C(i,j)$ of a confusion matrix counts the number of instances of class $i$ that were predicted as class $j$. When things are going well, the elements on the diagonal of $C$ are large, and the off-diagonal elements are small. Since there are 8 classes, $C$ will be $8 \\times 8$. The accuracy, or percent of correctly classified images, is given by the trace of $C$ divided by the sum of $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb82ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1da8d3b8b10f7d4168ec44b31082346",
     "grade": false,
     "grade_id": "cell-5400ddbf4b5a9cde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.1.1 (10 Points -> 5 Autograder + 5 WriteUp)\n",
    "Implement the function\n",
    "```\n",
    "            def evaluate_recognition_system():\n",
    "```\n",
    "that tests the system and outputs the confusion matrix.\n",
    "\n",
    "Report the confusion matrix and accuracy for your results in your write-up. This does not have to be formatted prettily: if you are using LaTeX, you can simply copy/paste it into a $verbatim$ environment. Additionally, do not worry if your accuracy is low: with 8 classes, chance is $12.5\\%$. To give you a more sensible number, a reference implementation _with_ spatial pyramid matching gives an overall accuracy of around $50\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826e61ed",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "760da0cf8ad862bfc65a4c8f6f4af5c7",
     "grade": false,
     "grade_id": "cell-7f6a78a4e33d1ca4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def helper_func(args):\n",
    "    file_path, dictionary, layer_num, K, trained_features, train_labels = args\n",
    "    \n",
    "    _, feature = get_image_feature(file_path, dictionary, layer_num, K)\n",
    "    distances = distance_to_set(feature, trained_features)\n",
    "    nearest_image_idx = np.argmax(distances)\n",
    "    pred_label = train_labels[nearest_image_idx]   \n",
    "    \n",
    "    return [file_path, pred_label, nearest_image_idx]\n",
    "\n",
    "\n",
    "def evaluate_recognition_system(num_workers=2):\n",
    "    '''\n",
    "    Evaluates the recognition system for all test images and returns the confusion matrix.\n",
    "\n",
    "    [input]\n",
    "    * num_workers: number of workers to process in parallel\n",
    "\n",
    "    [output]\n",
    "    * conf: numpy.ndarray of shape (8,8)\n",
    "    * accuracy: accuracy of the evaluated system\n",
    "    '''\n",
    "    '''\n",
    "    HINTS\n",
    "    (1) You may wish to use multiprocessing to improve speed (NO Extra Points)\n",
    "    (2) You may create helper function (in the same cell) to enable multiprocessing\n",
    "    (3) Think Nearest Neighbor -> assign label using element closest in train set\n",
    "    '''\n",
    "    \n",
    "    test_data = np.load(\"./data/test_data.npz\")\n",
    "    trained_system = np.load(\"trained_system.npz\")\n",
    "    \n",
    "    image_names = test_data['files']\n",
    "    test_labels = test_data['labels']\n",
    "\n",
    "    trained_features = trained_system['features']\n",
    "    train_labels = trained_system['labels']\n",
    "    \n",
    "    dictionary = trained_system['dictionary']\n",
    "    SPM_layer_num = trained_system['SPM_layer_num']\n",
    "    SPM_layer_num = int(SPM_layer_num)\n",
    "    K = dictionary.shape[0]\n",
    "\n",
    "    print(\"Trained features shape: \", trained_features.shape)\n",
    "    print(\"Test data shape: \", image_names.shape)\n",
    "\n",
    "    '''\n",
    "    HINTS:\n",
    "    1.> Think almost exactly similar to Q1.2.2\n",
    "    2.> Create a list of arguments and use multiprocessing library\n",
    "    3.> We can define a helper function which can take in the arguments (file_path, dictionary, SPM_layer_num,\n",
    "        trained_features,...) as input and return (file_path, label, nearest neighbor index)\n",
    "    4.> We can use python dictionary and file_path to have the output in correct order\n",
    "    '''\n",
    "    num_images = len(image_names)\n",
    "    list_of_args = []\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        full_image_name = './data/' + image_names[i]\n",
    "        list_of_args.append([full_image_name, dictionary, SPM_layer_num, K, trained_features, train_labels])\n",
    "    \n",
    "    with multiprocessing.Pool(num_workers) as p:\n",
    "        out = p.map(helper_func, list_of_args)\n",
    "       \n",
    "    '''\n",
    "    HINTS:\n",
    "    1.> Can use the file_name (path) to place the labels back in original order of input to multiprocessing\n",
    "    '''\n",
    "    \n",
    "    ordered_labels = [label for path, label, _ in out]\n",
    "    indices = [index for _, _, index in out]\n",
    "    \n",
    "    ordered_labels = np.array(ordered_labels, dtype=int)\n",
    "    \n",
    "    print(\"Predicted labels shape: \", ordered_labels.shape)\n",
    "    \n",
    "    '''\n",
    "    HINT:\n",
    "    1.> Compute the confusion matrix (8x8)\n",
    "    2.> Remember to save and upload the confusion matrix\n",
    "    '''    \n",
    "    conf_matrix = np.zeros((8, 8))\n",
    "    \n",
    "    assert ordered_labels.shape[0] == test_labels.shape[0]\n",
    "    \n",
    "    for i in range(ordered_labels.shape[0]):        \n",
    "        conf_matrix[test_labels[i], ordered_labels[i]] += 1\n",
    "        \n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)    \n",
    "    np.save(\"./conf_matrix.npy\", conf_matrix)\n",
    "    \n",
    "    return conf_matrix, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "701e7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_mat, accuracy = evaluate_recognition_system(2)\n",
    "\n",
    "# print(f'{accuracy = }')\n",
    "# print(f'{conf_mat = }')\n",
    "\n",
    "# plt.matshow(conf_mat)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c86fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "427973e4258d05e7dab0993c06bb805d",
     "grade": false,
     "grade_id": "cell-29cb1f1fda7fe0e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font color=\"blue\">**Submit the Confusion Matrix and the Accuracy Value in the WriteUp**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23665b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8bbe72feb9acd4b2f967821a1898c893",
     "grade": false,
     "grade_id": "cell-17f9ee303096151f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.1.2 (5 points WriteUp):\n",
    "<font color=\"blue\"> As there are some classes/samples that are more difficult to classify than the rest using the bags-of-words approach, they are more easily classified incorrectly into other categories. **List some of these classes/samples and discuss why they are more difficult in your write-up.** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe3fc5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c3ce1f7bea3a2fe4d4e6dd7cc4d5ed2",
     "grade": false,
     "grade_id": "cell-62c3ca3a5bf0dda0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q3.1.3 [Extra Credit](10 points) Manually Graded:\n",
    "\n",
    "Now that you have seen how well your recognition system can perform on a set of real images, you can experiment with different ways of improving this baseline system. Here are a few suggestions:\n",
    "\n",
    "* Hyperparameter Tuning: here is a list of hypterparameters in the system that you can tune to get better performance for your system:\n",
    "        \n",
    "        * `filter_scales`: a list of filter scales used in extracting filter response;\n",
    "        * `K`: the number of visual words and also the size of the dictionary;\n",
    "        * `alpha`: the number of sampled pixels in each image when creating the dictionary;\n",
    "        * `L`: the number of spatial pyramid layers used in feature extraction.\n",
    "        \n",
    "* Image manipulation: Try using image augmentation techniques such as random-crop, flipping, etc. to obtain more training data for your system. You can also try resizing the images, subtracting the mean color, etc. \n",
    "\n",
    "* Better classifier: in part 2 we used the nearest neighbor classifier to classify test images. However, with our extracted SPM features from training images, we can use other classifiers such as multi-class logistic regression, multi-class support vector machine, etc. to gain better performance. For this, you can use implementation of these algorithms from `scipy`.\n",
    "\n",
    "\n",
    "Tune the system you build to reach around 65\\% accuracy on the provided test set (``data/test_data.npz``). <font color=\"blue\">**In your writeup, document what you did to achieve such performance: (1) what you did, (2) what you expected would happen, and (3) what actually happened.** Also, include a file called ``custom.py/ipynb`` for running your code. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90920270",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae35d0b0f86d3d2c3d5b4952394f4c17",
     "grade": false,
     "grade_id": "cell-a0d3c7383fe4f8cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q3.1.4 [Extra Credit] (10 points):\n",
    "**Inverse Document Frequency:** With the bag-of-word model, image recognition is similar to classifying a document with words. In document classification, inverse document frequency (IDF) factor is incorporated which diminishes the weight of terms that occur very frequently in the document set. For example, because the term \"the\" is so common, this will tend to incorrectly emphasize documents which happen to use the word \"the\" more frequently, without giving enough weight to the more meaningful terms.\n",
    "\n",
    "In the homework, the histogram we computed only considers the term frequency (TF), i.e.  the number of times that word occurs in the word map.  Now we want to weight the word by its inverse document frequency.  The IDF of a word is defined as:\n",
    "\n",
    "\\begin{align*} IDF_w &= log \\frac{T}{|\\{d: w \\in\n",
    "d\\}|}\\\\ \\end{align*}\n",
    "\n",
    "Here, $T$ is number of all training images, and $|\\{d:w\\in d\\}|$ is the number of images $d$ such that $w$ occurs in that image.\n",
    "\n",
    "Write a function ``compute_IDF`` to compute a vector ``IDF`` of size $1\\times K$ containing IDF for all visual words, where K is the dictionary size. Save the extracted ``IDF`` in ``idf.npy``. Then write another function ``evaluate_recognition_System_IDF`` that makes use of the ``IDF`` vector in the recognition process. You can use either nearest neighbor or anything you have from q3.1.4 as your classifier.\n",
    "\n",
    "<font color=\"blue\">**In your writeup: How does Inverse Document Frequency affect the performance? Better or worse? Explain your reasoning?**\n",
    "\n",
    "**Remember to submit idf.npy along with the submission**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2333b1bb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89aace2648791b30734e812d44bc7e46",
     "grade": true,
     "grade_id": "cell-3debc253c7bf7c0c",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_single_idf(args):\n",
    "    file_path, dictionary, layer_num, K, trained_features, train_labels, idf = args\n",
    "    \n",
    "    n_patches = int(trained_features.shape[1] / K)\n",
    "    \n",
    "    # this will tile it 21 times as count columns and then flatten it to match the features.\n",
    "    idf_hist_all = np.repeat(idf.reshape(-1, 1), n_patches).flatten()\n",
    "    \n",
    "    _, feature = get_image_feature(file_path, dictionary, layer_num, K)\n",
    "    distances = distance_to_set(feature * idf_hist_all, trained_features * idf_hist_all)\n",
    "    pred_label = train_labels[np.argmax(distances)]   \n",
    "    \n",
    "    return pred_label  \n",
    "\n",
    "def compute_IDF():\n",
    "    trained_system = np.load(\"trained_system.npz\")\n",
    "    trained_features = trained_system['features']\n",
    "    dictionary = trained_system['dictionary']\n",
    "    \n",
    "    K = dictionary.shape[0]\n",
    "    T = trained_features.shape[0]\n",
    "    \n",
    "    word_count = np.sum(trained_features != 0, axis = 0)\n",
    "    idf = np.zeros((K))\n",
    "    n_patches = int(word_count.shape[0] / K)\n",
    "    j = 0\n",
    "    \n",
    "    idf_hist_all = np.log(T / word_count)\n",
    "    \n",
    "    for i in range(0, word_count.shape[0], n_patches):\n",
    "        idf[j] = word_count[i]\n",
    "        j += 1\n",
    "    \n",
    "    assert idf.shape[0] == K\n",
    "    np.save('idf.npy', idf)\n",
    "    \n",
    "    return idf\n",
    "\n",
    "def evaluate_recognition_System_IDF():\n",
    "    test_data = np.load(\"./data/test_data.npz\")\n",
    "    trained_system = np.load(\"trained_system.npz\")\n",
    "    \n",
    "    image_names = test_data['files']\n",
    "    test_labels = test_data['labels']\n",
    "\n",
    "    trained_features = trained_system['features']\n",
    "    train_labels = trained_system['labels']\n",
    "    \n",
    "    dictionary = trained_system['dictionary']\n",
    "    SPM_layer_num = trained_system['SPM_layer_num']\n",
    "    SPM_layer_num = int(SPM_layer_num)\n",
    "    K = dictionary.shape[0]\n",
    "\n",
    "    print(\"Trained features shape: \", trained_features.shape)\n",
    "    print(\"Test data shape: \", image_names.shape)\n",
    "\n",
    "    idf = compute_IDF()\n",
    "    \n",
    "    num_images = len(image_names)\n",
    "    ordered_labels = []\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        full_image_name = './data/' + image_names[i]\n",
    "        ordered_labels.append(evaluate_single_idf([full_image_name,\n",
    "                                                   dictionary,\n",
    "                                                   3,\n",
    "                                                   K,\n",
    "                                                   trained_features,\n",
    "                                                   train_labels,\n",
    "                                                   idf.reshape(1, -1)]))\n",
    "        \n",
    "    \n",
    "    ordered_labels = np.array(ordered_labels, dtype=int)\n",
    "    assert ordered_labels.shape[0] == test_labels.shape[0]    \n",
    "    \n",
    "    conf_matrix = np.zeros((8, 8))\n",
    "    \n",
    "    for i in range(ordered_labels.shape[0]):\n",
    "        conf_matrix[test_labels[i], ordered_labels[i]] += 1\n",
    "        \n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)    \n",
    "    np.save(\"./conf_matrix.npy\", conf_matrix)\n",
    "    \n",
    "    return conf_matrix, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44d98375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained features shape:  (1000, 4200)\n",
      "Test data shape:  (160,)\n",
      "accuracy = 0.6\n",
      "conf_mat = array([[14.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., 12.,  1.,  2.,  0.,  1.,  2.,  0.],\n",
      "       [ 0.,  1., 12.,  4.,  1.,  4.,  1.,  2.],\n",
      "       [ 0.,  3.,  2., 13.,  0.,  1.,  3.,  4.],\n",
      "       [ 2.,  0.,  1.,  0.,  9.,  1.,  0.,  0.],\n",
      "       [ 2.,  0.,  0.,  2.,  7., 11.,  2.,  0.],\n",
      "       [ 1.,  1.,  0.,  0.,  2.,  2., 15.,  0.],\n",
      "       [ 0.,  0.,  1.,  6.,  2.,  0.,  0., 10.]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# conf_mat, accuracy = evaluate_recognition_System_IDF()\n",
    "\n",
    "# print(f'{accuracy = }')\n",
    "# print(f'{conf_mat = }')\n",
    "\n",
    "# plt.matshow(conf_mat)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185d921",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c362e00628e6d24678258560cff5ea75",
     "grade": true,
     "grade_id": "q_3_1_1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec934e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
